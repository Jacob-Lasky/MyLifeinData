{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://www.geeksforgeeks.org/python-fetch-your-gmail-emails-from-a-particular-user/\n",
    "# I am only getting the initial email sent, I do not know how this will work with forwarded emails or reply chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imaplib, email \n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "###!!! DO NOT UPLOAD WITH THIS !!!###\n",
    "\n",
    "## DO NOT UPLOAD TO GITHUB WITH THIS EITHER ##\n",
    "user  = \"USER_NAME\"\n",
    "password = \"PASSWORD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "imap_url = 'imap.gmail.com'\n",
    "    \n",
    "# Function to search for a key value pair  \n",
    "def search(key, value, con):  \n",
    "    result, data = con.search(None, key, '\"{}\"'.format(value)) \n",
    "    return data \n",
    "  \n",
    "# Function to get the list of emails under this label \n",
    "def get_emails(result_bytes): \n",
    "    msgs = [] # all the email data are pushed inside an array \n",
    "    for num in result_bytes[0].split(): \n",
    "        typ, data = con.fetch(num, '(RFC822)') \n",
    "        msgs.append(data) \n",
    "  \n",
    "    return msgs \n",
    "  \n",
    "# this is done to make SSL connnection with GMAIL \n",
    "con = imaplib.IMAP4_SSL(imap_url)  \n",
    "  \n",
    "# logging the user in \n",
    "con.login(user, password)  \n",
    "  \n",
    "# calling function to check for email under this label \n",
    "con.select('Inbox')  \n",
    "\n",
    " # fetching emails from this user\n",
    "msgs = get_emails(search('SUBJECT', 'MOOD', con)) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Content-Type: text/plain; charset=\"UTF-8\"\r\n",
      "\r\n",
      "9-12-19: 07.24\r\n",
      "Valence: 7\r\n",
      "Arousal: 7\r\n",
      "Inspiration: 8\r\n",
      "\r\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# msgs is a list of all emails\n",
    "body = str(msgs[0][0][1], 'utf-8')\n",
    "\n",
    "# get the start of our 'boundary' tag, so we can identify the body of the email\n",
    "l_bound = body.find('; boundary=\"') + 12 # add 12 because that's len('; boundary=\"')\n",
    "\n",
    "# get the end of our 'boundary' tag\n",
    "r_bound = body.find('\"', l_bound)\n",
    "\n",
    "# get the ID of where our body starts and stops\n",
    "body_id = body[l_bound:r_bound]\n",
    "\n",
    "# split our email on the body_id, and get the content (2nd element)\n",
    "# FYI: 2nd element is plain text and 3rd element is HTML\n",
    "print(body.split(body_id)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "message_contents = []\n",
    "# printing them by date received \n",
    "for i, msg in enumerate(msgs):  \n",
    "    for content in msg: \n",
    "        if type(content) is tuple:\n",
    "  \n",
    "            # Handling errors related to unicodenecode \n",
    "            try:  \n",
    "                full_email = str(content[1], 'utf-8')\n",
    "            except UnicodeEncodeError as e: \n",
    "                pass\n",
    "            \n",
    "    # get the start of our 'boundary' tag, so we can identify the body of the email\n",
    "    l_bound = full_email.find('; boundary=\"') + 12 # add 12 because that's len('; boundary=\"')\n",
    "\n",
    "    # get the end of our 'boundary' tag\n",
    "    r_bound = full_email.find('\"', l_bound)\n",
    "\n",
    "    # get the ID of where our body starts and stops\n",
    "    body_id = full_email[l_bound:r_bound]\n",
    "\n",
    "    # split our email on the body_id, and get the content (2nd element)\n",
    "    # FYI: 2nd element is plain text and 3rd element is HTML\n",
    "    try:\n",
    "        body = full_email.split(body_id)[2]\n",
    "    except:\n",
    "        body = \"Email could not be read: {0}\".format(i)        \n",
    "    message_contents.append(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_dat = []\n",
    "\n",
    "for content in message_contents:\n",
    "    # check to make sure we didn't have an error when reading the email\n",
    "    # len(\"Email could not be read: \") = 25\n",
    "    if \"Email could not be read: \" == content[:25]:\n",
    "        raw_dat.append([content, None, None, None, None])\n",
    "        continue\n",
    "    \n",
    "    # split the body based on our new lines\n",
    "    body_split = content.replace(\"\\r\", \"\").splitlines()\n",
    "\n",
    "    # get our date and time that we sent this\n",
    "    # take the third line, which is our date\n",
    "    date_time_raw = body_split[3]\n",
    "\n",
    "    # turn our date and time strings into a standard date time object\n",
    "    date_time = dt.datetime.strptime(date_time_raw, \"%m-%d-%y: %H.%M\")\n",
    "\n",
    "    # turn our date_time object into an easily understood string\n",
    "    date_time = date_time.strftime(\"%Y/%m/%d %H:%M\")\n",
    "\n",
    "    # get our valance, arousal, and inspiration\n",
    "    # go through each line of our email\n",
    "    val = None\n",
    "    aro = None\n",
    "    ins = None\n",
    "    note = None\n",
    "    for lines in body_split:\n",
    "        # find our key/val delimeter (\": \"), it will be -1 if it is missing\n",
    "        if lines.find(\": \") == -1:\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            key, value = lines.split(\": \")\n",
    "            if key == \"Valence\":\n",
    "                val = value\n",
    "            \n",
    "            elif key == \"Arousal\":\n",
    "                aro = value\n",
    "                \n",
    "            elif key == \"Inspiration\":\n",
    "                ins = value\n",
    "                \n",
    "            elif key == \"Note\":\n",
    "                note = value\n",
    "\n",
    "    raw_dat.append([date_time, val, aro, ins, note])\n",
    "    \n",
    "emotions = pd.DataFrame(columns=[\"Date\", \"Valence\", \"Arousal\", \"Inspiration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2019/09/12 07:24', '7', '7', '8', None],\n",
       " ['2019/09/12 09:43', '8', '9', '6', None],\n",
       " ['2019/09/12 12:08', '6', '5', '4', None],\n",
       " ['2019/09/12 22:26', '5', '2', '1', None],\n",
       " ['2019/09/13 06:45', '3', '5', '0', None],\n",
       " ['2019/09/13 23:08', '4', '1', '2', None],\n",
       " ['2019/09/14 09:00', '5', '4', '0', None],\n",
       " ['2019/09/14 13:18', '2', '2', '0', None],\n",
       " ['2019/09/14 16:06', '8', '7', '1', None],\n",
       " ['2019/09/15 00:24', '8', '2', '0', None],\n",
       " ['2019/09/15 08:37', '6', '3', '3', None],\n",
       " ['2019/09/15 13:12', '0', '7', '1', None],\n",
       " ['2019/09/15 23:23', '4', '2', '0', None],\n",
       " ['2019/09/16 07:41', '5', '4', '5', None],\n",
       " ['2019/09/16 14:06', '6', '5', '5', None],\n",
       " ['2019/09/16 22:36', '6', '3', '1', None],\n",
       " ['2019/09/17 16:27', '5', '2', '1', None],\n",
       " ['2019/09/17 23:06', '4', '4', '4', None],\n",
       " ['2019/09/18 06:39', '2', '3', '0', None],\n",
       " ['2019/09/18 22:34', '9', '2', '1', None],\n",
       " ['2019/09/19 08:52', '3', '3', '0', None],\n",
       " ['2019/09/20 07:08', '3', '5', '1', None],\n",
       " ['2019/09/20 22:54', '6', '1', '0', None],\n",
       " ['2019/09/21 10:55', '9', '8', '4', None],\n",
       " ['2019/09/21 23:18', '6', '0', '0', None],\n",
       " ['2019/09/22 09:05', '7', '3', '0', None],\n",
       " ['2019/09/22 22:57', '8', '4', '4', None],\n",
       " ['2019/09/23 07:10', '5', '2', '0', None],\n",
       " ['2019/09/23 22:56', '6', '1', '0', None],\n",
       " ['2019/09/24 07:51', '6', '1', '1', None],\n",
       " ['2019/09/24 23:44', '7', '3', '2', None],\n",
       " ['2019/09/25 09:27', '6', '0', '0', None],\n",
       " ['2019/09/25 22:01', '7', '3', '8', None],\n",
       " ['2019/09/26 08:01', '8', '7', '6', None],\n",
       " ['2019/09/26 08:55', '2', '0', None, 'Not talkative'],\n",
       " ['2019/09/26 14:28', '7', '2', '8', '%notes'],\n",
       " ['2019/09/26 22:43', '8', '4', None, 'None'],\n",
       " ['2019/09/26 22:43', '8', '4', '7', 'Sick'],\n",
       " ['2019/09/27 06:51', '5', '1', '1', '%notes'],\n",
       " ['2019/09/27 08:03', '2', '5', None, 'Annoyed'],\n",
       " ['2019/09/27 23:19', '5', '5', None, 'None'],\n",
       " ['2019/09/27 23:20', '7', '6', '4', 'mad now'],\n",
       " ['2019/09/28 09:29', '4', '5', '3', '%notes'],\n",
       " ['2019/09/29 00:05', '8', '4', '0', 'None'],\n",
       " ['2019/09/29 00:06', '7', '5', None, 'was sad but now better'],\n",
       " ['2019/09/29 10:14', '6', '5', '5', '!s'],\n",
       " ['2019/09/29 23:41', '6', '5', '3', 'dad in town'],\n",
       " ['2019/09/30 00:09', '4', '2', None, 'None'],\n",
       " ['2019/10/01 07:17', '6', '6', '5', 'None'],\n",
       " ['2019/10/02 22:57', '10', '6', '3', 'time with dad and Grandpa'],\n",
       " ['2019/10/03 22:41', '7', '4', '5', 'None'],\n",
       " ['2019/10/05 10:43', '8', '7', '7', 'None'],\n",
       " ['2019/10/06 00:11', '9', '9', '8', 'None'],\n",
       " ['2019/10/06 10:14', '4', '3', '3', '/s'],\n",
       " ['2019/10/06 23:37', '9', '6', '6', 'None'],\n",
       " ['2019/10/07 01:33', '8', '4', None, 'None'],\n",
       " ['2019/10/07 07:35', '6', '0', '0', '/s'],\n",
       " ['2019/10/07 22:59', '7', '4', '8', 'None'],\n",
       " ['2019/10/07 23:00', '9', '7', None, 'Dieting'],\n",
       " ['2019/10/08 07:27', '9', '2', '1', 'None'],\n",
       " ['2019/10/08 07:28', '8', '2', None, 'None'],\n",
       " ['2019/10/09 07:46', '4', '4', '5', '/s !s'],\n",
       " ['2019/10/09 21:57', '3', '0', '0', 'feeling run down'],\n",
       " ['2019/10/09 21:58', '4', '1', None, 'sad'],\n",
       " ['2019/10/10 07:59', '7', '2', '4', 'tired'],\n",
       " ['2019/10/10 23:50', '6', '7', '3', 'None'],\n",
       " ['2019/10/11 07:01', '1', '5', '1', 'mad'],\n",
       " ['2019/10/11 23:55', '7', '2', '4', 'bad tourettes'],\n",
       " ['2019/10/12 09:30', '4', '4', '2', 'None'],\n",
       " ['2019/10/13 00:13', '6', '2', '1', 'None'],\n",
       " ['2019/10/13 00:13', '7', '5', None, 'None'],\n",
       " ['2019/10/13 11:42', '2', '6', '6', 'None'],\n",
       " ['2019/10/13 23:35', '4', '5', '2', 'None'],\n",
       " ['2019/10/14 07:34', '6', '4', '3', 'None'],\n",
       " ['2019/10/14 22:49', '7', '4', '3', 'fasting'],\n",
       " ['2019/10/15 06:49', '5', '2', '1', 'head ache'],\n",
       " ['2019/10/15 22:43', '6', '2', '3', 'None'],\n",
       " ['2019/10/16 07:02', '3', '6', '3', 'Monica mad'],\n",
       " ['2019/10/17 08:07', '5', '2', '0', 'None'],\n",
       " ['2019/10/17 22:53', '7', '3', '6', 'None'],\n",
       " ['2019/10/18 06:55', '4', '6', '1', 'None'],\n",
       " ['Email could not be read: 81', None, None, None, None],\n",
       " ['Email could not be read: 82', None, None, None, None],\n",
       " ['Email could not be read: 83', None, None, None, None],\n",
       " ['Email could not be read: 84', None, None, None, None],\n",
       " ['Email could not be read: 85', None, None, None, None],\n",
       " ['Email could not be read: 86', None, None, None, None],\n",
       " ['Email could not be read: 87', None, None, None, None],\n",
       " ['Email could not be read: 88', None, None, None, None],\n",
       " ['Email could not be read: 89', None, None, None, None],\n",
       " ['Email could not be read: 90', None, None, None, None],\n",
       " ['Email could not be read: 91', None, None, None, None],\n",
       " ['Email could not be read: 92', None, None, None, None],\n",
       " ['Email could not be read: 93', None, None, None, None],\n",
       " ['Email could not be read: 94', None, None, None, None],\n",
       " ['Email could not be read: 95', None, None, None, None],\n",
       " ['Email could not be read: 96', None, None, None, None],\n",
       " ['Email could not be read: 97', None, None, None, None],\n",
       " ['Email could not be read: 98', None, None, None, None],\n",
       " ['Email could not be read: 99', None, None, None, None],\n",
       " ['Email could not be read: 100', None, None, None, None],\n",
       " ['Email could not be read: 101', None, None, None, None],\n",
       " ['Email could not be read: 102', None, None, None, None],\n",
       " ['2019/10/29 22:11', '1', '2', '3', 'None'],\n",
       " ['2019/10/30 07:12', '2', '2', '0', 'None'],\n",
       " ['2019/10/30 22:40', '3', '1', '0', 'None'],\n",
       " ['2019/10/31 07:00', '5', '5', '6', 'windows open'],\n",
       " ['2019/10/31 22:34', '7', '8', '7', 'had coffee'],\n",
       " ['2019/11/01 06:57', '7', '7', '2', 'None'],\n",
       " ['2019/11/01 23:59', '6', '4', '2', 'None'],\n",
       " ['2019/11/02 11:02', '8', '8', '7', 'None'],\n",
       " ['2019/11/03 01:47', '8', '7', '1', 'None'],\n",
       " ['2019/11/03 09:45', '4', '7', '7', 'None'],\n",
       " ['2019/11/03 22:22', '6', '8', '4', 'None'],\n",
       " ['2019/11/04 06:42', '4', '3', '1', '79% sleep score'],\n",
       " ['2019/11/04 22:36', '7', '8', '9', 'None'],\n",
       " ['2019/11/05 14:25', '6', '6', '1', 'None'],\n",
       " ['2019/11/06 07:19', '7', '5', '5', 'None'],\n",
       " ['2019/11/06 22:49', '9', '8', '9', 'None'],\n",
       " ['2019/11/07 07:04', '5', '6', '9', 'hungover'],\n",
       " ['2019/11/08 04:44', '7', '2', '1', 'None'],\n",
       " ['2019/11/08 13:15', '5', '4', '7', 'None'],\n",
       " ['2019/11/08 23:58', '4', '1', '0', 'None'],\n",
       " ['2019/11/09 11:00', '7', '8', None, 'socializing tonight'],\n",
       " ['2019/11/10 02:02', '9', '7', '5', 'socialized'],\n",
       " ['2019/11/10 02:03', '7', '7', None, 'feels bad now'],\n",
       " ['2019/11/10 10:55', '6', '6', '4', 'None'],\n",
       " ['2019/11/10 13:21', '4', '4', None, 'None'],\n",
       " ['2019/11/11 00:03', '8', '7', '6', 'None'],\n",
       " ['2019/11/11 07:21', '5', '2', '0', 'None'],\n",
       " ['2019/11/11 07:40', '6', '6', None, 'None'],\n",
       " ['2019/11/12 00:41', '8', '4', '1', 'None'],\n",
       " ['2019/11/12 08:11', '5', '1', '2', 'None'],\n",
       " ['2019/11/13 07:35', '5', '6', '3', 'None'],\n",
       " ['2019/11/14 07:45', '6', '5', '5', 'None'],\n",
       " ['2019/11/14 23:33', '2', '3', '0', 'None'],\n",
       " ['2019/11/15 08:31', '7', '6', '3', 'None'],\n",
       " ['2019/11/16 00:03', '2', '3', '6', 'None'],\n",
       " ['2019/11/16 09:08', '5', '6', '6', 'None'],\n",
       " ['2019/11/17 02:41', '8', '6', '7', 'None'],\n",
       " ['2019/11/17 09:53', '3', '1', '6', 'None'],\n",
       " ['2019/11/17 22:28', '5', '3', '6', 'Monica in pain'],\n",
       " ['2019/11/18 07:33', '3', '7', '5', 'None'],\n",
       " ['2019/11/18 23:03', '5', '7', '4', 'mad during meeting'],\n",
       " ['2019/11/19 12:48', '6', '1', '1', 'None'],\n",
       " ['2019/11/19 22:42', '7', '1', '3', 'None'],\n",
       " ['2019/11/20 07:30', '5', '2', '1', 'None'],\n",
       " ['2019/11/20 22:57', '5', '4', '8', 'Monica getting mad easily'],\n",
       " ['2019/11/21 07:22', '6', '3', '5', 'None'],\n",
       " ['2019/11/21 23:42', '5', '1', '0', 'None'],\n",
       " ['2019/11/22 09:16', '7', '2', '5', '!s'],\n",
       " ['2019/11/23 01:03', '6', '3', '8', 'None'],\n",
       " ['2019/11/23 09:30', '5', '6', '6', 'None'],\n",
       " ['2019/11/24 04:01', '6', '4', '4', 'None'],\n",
       " ['2019/11/24 11:00', '7', '3', '5', 'None'],\n",
       " ['2019/11/25 01:05', '5', '6', '6', '/s'],\n",
       " ['2019/11/25 10:03', '5', '3', '6', 'None'],\n",
       " ['2019/11/25 22:40', '6', '1', '1', 'None'],\n",
       " ['2019/11/26 07:23', '4', '1', '5', '/s'],\n",
       " ['2019/11/27 00:44', '8', '3', '1', 'None'],\n",
       " ['2019/11/27 10:15', '8', '8', '3', 'excited'],\n",
       " ['2019/11/27 23:59', '8', '8', '8', 'excited'],\n",
       " ['2019/11/28 10:28', '6', '6', '2', 'None'],\n",
       " ['2019/11/28 21:24', '8', '4', '3', 'None'],\n",
       " ['2019/11/29 08:22', '4', '5', '3', 'None'],\n",
       " ['2019/11/30 01:45', '10', '7', '6', 'family'],\n",
       " ['2019/11/30 10:22', '6', '7', '6', 'None'],\n",
       " ['2019/12/01 10:03', '3', '5', '5', 'sad to be leaving'],\n",
       " ['2019/12/01 22:32', '4', '4', '1', 'None'],\n",
       " ['2019/12/02 07:49', '6', '6', '3', 'None'],\n",
       " ['2019/12/02 09:35', '7', '4', '5', 'None'],\n",
       " ['2019/12/02 23:22', '6', '7', '4', 'None'],\n",
       " ['2019/12/03 09:35', '5', '4', '3', 'None'],\n",
       " ['2019/12/03 23:12', '7', '2', '2', 'None'],\n",
       " ['2019/12/04 08:22', '6', '2', '0', 'None'],\n",
       " ['2019/12/04 23:45', '6', '7', '7', 'None'],\n",
       " ['2019/12/05 09:01', '6', '3', '1', 'sick'],\n",
       " ['2019/12/05 23:10', '7', '3', '0', 'None'],\n",
       " ['2019/12/07 02:17', '7', '4', '1', 'None'],\n",
       " ['2019/12/07 11:01', '7', '6', '6', 'None'],\n",
       " ['2019/12/08 00:46', '9', '7', '6', 'None'],\n",
       " ['2019/12/08 12:09', '5', '6', '1', 'None'],\n",
       " ['2019/12/08 23:43', '7', '4', '1', 'None'],\n",
       " ['2019/12/09 08:39', '5', '2', '6', 'None'],\n",
       " ['2019/12/09 22:58', '6', '2', '3', 'None'],\n",
       " ['2019/12/10 07:00', '8', '8', '9', 'None'],\n",
       " ['2019/12/10 22:16', '7', '4', '9', 'None'],\n",
       " ['2019/12/11 07:28', '6', '2', '6', 'None'],\n",
       " ['2019/12/11 22:25', '7', '6', '9', 'None'],\n",
       " ['2019/12/12 07:22', '8', '7', '7', 'None'],\n",
       " ['2019/12/12 22:50', '7', '6', '7', 'None'],\n",
       " ['2019/12/13 08:10', '5', '4', '4', 'None'],\n",
       " ['2019/12/14 00:25', '6', '7', '7', 'None'],\n",
       " ['2019/12/14 09:22', '4', '5', '3', 'None'],\n",
       " ['2019/12/14 23:31', '6', '5', '7', 'None'],\n",
       " ['2019/12/15 10:05', '7', '6', '4', 'None'],\n",
       " ['2019/12/15 23:02', '6', '3', '6', 'None'],\n",
       " ['2019/12/16 07:46', '5', '6', '7', 'None'],\n",
       " ['2019/12/16 22:46', '5', '4', '5', 'None'],\n",
       " ['2019/12/17 08:03', '5', '5', '6', 'None'],\n",
       " ['2019/12/17 22:37', '2', '3', '1', 'None'],\n",
       " ['2019/12/18 07:21', '5', '4', '4', 'None'],\n",
       " ['2019/12/18 22:49', '6', '5', '8', 'None'],\n",
       " ['2019/12/19 08:02', '6', '6', '7', 'None'],\n",
       " ['2019/12/19 23:57', '7', '7', '8', 'None'],\n",
       " ['2019/12/20 07:45', '6', '4', '5', 'None'],\n",
       " ['2019/12/21 00:23', '3', '7', '9', 'None'],\n",
       " ['2019/12/21 23:46', '7', '8', '6', 'None'],\n",
       " ['2019/12/22 09:17', '6', '7', '7', 'None'],\n",
       " ['2019/12/22 23:03', '9', '9', '8', 'happy, with family'],\n",
       " ['2019/12/23 07:00', '6', '4', '3', 'None'],\n",
       " ['2019/12/23 22:55', '4', '6', '5', 'None'],\n",
       " ['2019/12/24 09:55', '5', '6', '3', 'None'],\n",
       " ['2019/12/24 23:49', '7', '4', '5', 'None'],\n",
       " ['2019/12/25 09:44', '8', '7', '6', 'None'],\n",
       " ['2019/12/25 23:13', '4', '6', '5', 'Brandon pissed me off'],\n",
       " ['2019/12/26 09:35', '6', '7', '7', 'None'],\n",
       " ['2019/12/27 01:17', '10', '9', '9', 'Games with friends'],\n",
       " ['2019/12/27 09:42', '7', '6', '7', 'None'],\n",
       " ['2019/12/28 00:07', '5', '5', '7', 'None'],\n",
       " ['2019/12/28 10:16', '6', '5', '5', 'None'],\n",
       " ['2019/12/29 01:06', '8', '5', '6', 'None'],\n",
       " ['2019/12/29 10:25', '5', '5', '3', 'None'],\n",
       " ['2019/12/29 23:52', '8', '7', '7', 'None'],\n",
       " ['2019/12/30 09:33', '5', '5', '6', 'None'],\n",
       " ['Email could not be read: 225', None, None, None, None],\n",
       " ['Email could not be read: 226', None, None, None, None],\n",
       " ['Email could not be read: 227', None, None, None, None],\n",
       " ['Email could not be read: 228', None, None, None, None],\n",
       " ['2020/01/02 09:20', '5', '4', '7', 'None'],\n",
       " ['2020/01/02 23:14', '8', '9', '9', 'None'],\n",
       " ['2020/01/03 08:18', '7', '8', '8', 'None'],\n",
       " ['2020/01/04 02:01', '7', '6', '9', 'None'],\n",
       " ['2020/01/04 12:33', '7', '9', '8', 'None'],\n",
       " ['2020/01/05 00:04', '7', '8', '8', 'None'],\n",
       " ['2020/01/05 14:34', '7', '5', '9', 'None'],\n",
       " ['2020/01/05 21:45', '6', '5', '7', 'Monica upset'],\n",
       " ['2020/01/06 07:39', '4', '5', '6', 'None'],\n",
       " ['2020/01/06 22:37', '6', '6', '3', 'Monica upset today'],\n",
       " ['2020/01/07 07:55', '6', '4', '5', 'None'],\n",
       " ['2020/01/07 22:04', '7', '6', '5', 'None'],\n",
       " ['2020/01/08 07:48', '6', '6', '5', 'None'],\n",
       " ['2020/01/08 22:47', '6', '6', '8', 'None'],\n",
       " ['2020/01/09 09:11', '8', '6', '6', 'None'],\n",
       " ['2020/01/09 22:20', '7', '5', '4', 'None'],\n",
       " ['2020/01/10 07:48', '5', '4', '6', 'None'],\n",
       " ['2020/01/10 23:22', '6', '1', '4', 'really tired'],\n",
       " ['2020/01/11 09:39', '5', '6', '6', 'None'],\n",
       " ['2020/01/12 00:13', '6', '6', '10', 'None'],\n",
       " ['2020/01/12 09:15', '7', '4', '5', 'None'],\n",
       " ['2020/01/12 22:26', '3', '2', '4', 'None'],\n",
       " ['2020/01/13 07:58', '5', '3', '4', 'None']]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
